{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Необходимо собрать информацию о вакансиях на вводимую должность (используем input или через аргументы)\n",
    "# с сайта superjob.ru и hh.ru. Приложение должно анализировать несколько страниц сайта(также вводим\n",
    "# через input или аргументы). Получившийся список должен содержать в себе минимум:\n",
    "#     * Наименование вакансии\n",
    "#     * Предлагаемую зарплату (отдельно мин. и отдельно макс.)\n",
    "#     * Ссылку на саму вакансию\n",
    "#     * Сайт откуда собрана вакансия\n",
    "# По своему желанию можно добавить еще работодателя и расположение. Данная структура должна быть одинаковая\n",
    "# для вакансий с обоих сайтов. Общий результат можно вывести с помощью dataFrame через pandas.Сохраните в json либо csv.\n",
    "\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html_page_text_from_hh(vacancy_name='Data analyst', direct_link=None):\n",
    "    \"\"\"Функция возвращает текст html-страницы с hh.ru по указанной вакансии.\n",
    "    По умолчанию - первую страницу поиска.\n",
    "    Также можно задать точную ссылку на следующую страницу.\n",
    "    Если с сервера вернулась ошибка, то функция возвращает None.\"\"\"\n",
    "\n",
    "    # Базовая ссылка\n",
    "    main_link = 'https://hh.ru'\n",
    "\n",
    "    params = {\n",
    "        'clusters': 'true',\n",
    "        'enable_snippets': 'true',\n",
    "        'salary': '',\n",
    "        'st': 'searchVacancy',\n",
    "        'text': vacancy_name,\n",
    "        'fromSearch': 'true'\n",
    "    }\n",
    "\n",
    "    # Заголовки Google Chrome\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
    "                      'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                      'Chrome/83.0.4103.61 Safari/537.36',\n",
    "        'Accept': '*/*'\n",
    "    }\n",
    "\n",
    "    # Запрос и ответ\n",
    "    if direct_link:\n",
    "        # прямая ссылка на страницу\n",
    "        link = main_link + direct_link\n",
    "        response = requests.get(link, headers=headers)\n",
    "    else:\n",
    "        # базовая ссылка\n",
    "        link = main_link + '/search/vacancy'\n",
    "        response = requests.get(link, params=params, headers=headers)\n",
    "\n",
    "    # Если ответ сервера 200 Ок, то берем данные\n",
    "    if response.ok:\n",
    "        return response.text\n",
    "    else:\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_salary_from_text(salary_string):\n",
    "    \"\"\"Функция парсит строку и возвращает три значения:\n",
    "    - минимальную границу зарплаты (int),\n",
    "    - максимальную границу зарплаты (int),\n",
    "    - наименование валюты.\"\"\"\n",
    "\n",
    "    # Варианты:\n",
    "    # до 140 000 руб.</span>\n",
    "    # от 80 000 руб.</span>\n",
    "    # 520-845 бел. руб.</span>\n",
    "    # 120 000-150 000 руб.</span>\n",
    "    # 250 000-500 000 KZT</span>\n",
    "\n",
    "    prepared_string = salary_string.replace('\\xa0', '')\n",
    "    prepared_string = prepared_string.replace(' ', '')\n",
    "\n",
    "    if prepared_string.startswith('до'):\n",
    "        # Парсим вариант \"до ...\"\n",
    "        result = re.findall(r'(\\d+)(\\w+\\.?\\w*\\.?)', prepared_string)\n",
    "        salary_from = None\n",
    "        try:\n",
    "            salary_currency = result[0][1]\n",
    "        except:\n",
    "            salary_currency = None\n",
    "        try:\n",
    "            salary_to = int(result[0][0])\n",
    "        except:\n",
    "            salary_to = None\n",
    "        return salary_from, salary_to, salary_currency\n",
    "\n",
    "    elif prepared_string.startswith('от'):\n",
    "        # Парсим вариант \"от ...\"\n",
    "        result = re.findall(r'(\\d+)(\\w+\\.?\\w*\\.?)', prepared_string)\n",
    "        salary_to = None\n",
    "        try:\n",
    "            salary_currency = result[0][1]\n",
    "        except:\n",
    "            salary_currency = None\n",
    "        try:\n",
    "            salary_from = int(result[0][0])\n",
    "        except:\n",
    "            salary_from = None\n",
    "        return salary_from, salary_to, salary_currency\n",
    "\n",
    "    else:\n",
    "        # Парсим вариант, когда указаны обе границы зарплаты\n",
    "        result = re.findall(r'(\\d+)-(\\d+)(\\w+\\.?\\w*\\.?)', prepared_string)\n",
    "        try:\n",
    "            salary_currency = result[0][2]\n",
    "        except:\n",
    "            salary_currency = None\n",
    "        try:\n",
    "            salary_from = int(result[0][0])\n",
    "        except:\n",
    "            salary_from = None\n",
    "        try:\n",
    "            salary_to = int(result[0][1])\n",
    "        except:\n",
    "            salary_to = None\n",
    "        return salary_from, salary_to, salary_currency\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаем вакансию для поиска\n",
    "# Data scientist, Data analyst\n",
    "searching_vacancy = 'Data scientist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список для сбора всех вакансий\n",
    "vacancies_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ссылка на следующую страницу\n",
    "next_page_link = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Бесконечный цикл прервется, когда будут просмотрены все страницы\n",
    "while True:\n",
    "\n",
    "    # Загружаем страницу с hh.ru\n",
    "    page_text = get_html_page_text_from_hh(searching_vacancy, next_page_link)\n",
    "\n",
    "    # Если есть положительный ответ от сервера с контентом\n",
    "    if page_text:\n",
    "\n",
    "        # Создаем суп и передаем текст страницы\n",
    "        soup = BeautifulSoup(page_text, 'lxml')\n",
    "\n",
    "        # Ищем div-ы с вакансиями\n",
    "        all_vacancies_divs = soup.find_all('div', attrs={'class': 'vacancy-serp-item'})\n",
    "\n",
    "        # Цикл по всем вакансиям\n",
    "        for vacancy_div in all_vacancies_divs:\n",
    "\n",
    "            # Информация о текущей вакансии\n",
    "            vacancy = {}\n",
    "\n",
    "            # Тэг <a> с названием вакансии и ссылкой\n",
    "            tag = vacancy_div.find('a', {'data-qa': 'vacancy-serp__vacancy-title'})\n",
    "            vacancy_title = tag.text\n",
    "            vacancy_link = tag['href']\n",
    "\n",
    "            # Тэг <a> с работодателем\n",
    "            tag = vacancy_div.find('a', {'data-qa': 'vacancy-serp__vacancy-employer'})\n",
    "            employer_name = tag.text.strip()\n",
    "\n",
    "            # Тэг <span> с адресом (здесь в span-е встречаются разные варианта контента)\n",
    "            tag = vacancy_div.find('span', {'data-qa': 'vacancy-serp__vacancy-address'})\n",
    "            employer_city = tag.contents[0]\n",
    "            employer_city = employer_city.split(',')[0]\n",
    "\n",
    "            # Тэг <span> с зарплатой\n",
    "            tag = vacancy_div.find('span', {'data-qa': 'vacancy-serp__vacancy-compensation'})\n",
    "            if tag:\n",
    "                # Зарплата указана\n",
    "                salary_info = get_salary_from_text(tag.text)\n",
    "            else:\n",
    "                # Зарплата не указана\n",
    "                salary_info = (None, None, None)\n",
    "\n",
    "            # Запись собранных данных\n",
    "            vacancy['source'] = 'hh.ru'\n",
    "            vacancy['title'] = vacancy_title\n",
    "            vacancy['link'] = vacancy_link\n",
    "            vacancy['employer'] = employer_name\n",
    "            vacancy['city'] = employer_city\n",
    "            vacancy['salary_min'] = salary_info[0]\n",
    "            vacancy['salary_max'] = salary_info[1]\n",
    "            vacancy['salary_currency'] = salary_info[2]\n",
    "\n",
    "            # Добавление вакансии в список\n",
    "            vacancies_data.append(vacancy)\n",
    "\n",
    "        # Ищем кнопку \"дальше\" для загрузки следующей страницы\n",
    "        more_button_tag = soup.find('a', {'data-qa': 'pager-next'})\n",
    "        if more_button_tag:\n",
    "            # Есть кнопка \"дальше\"\n",
    "            next_page_link = more_button_tag['href']\n",
    "        else:\n",
    "            # Просмотрели все страницы, выходим из бесконечного цикла\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запись всех собранных вакансий в файл\n",
    "output_filename = searching_vacancy.lower().replace(' ', '_') + '_vacancies.json'\n",
    "with open(output_filename, 'w', encoding='utf-8') as my_file:\n",
    "    json.dump(vacancies_data, my_file, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В файл data_scientist_vacancies.json сохранено 280 вакансий.\n"
     ]
    }
   ],
   "source": [
    "# Печать результатов\n",
    "print(f'В файл {output_filename} сохранено {len(vacancies_data)} вакансий.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
